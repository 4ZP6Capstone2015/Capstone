\section*{Appendix}
This section contains literate Haskell code and notes on implementation issues.
\subsection*{Literate Haskel Code}
%\include{Freshname}
\subsection*{Notes on Implementation Issues}

This section contains a detailed list of concerns that came to light during the 
course of software implementation, though some issues were addressed, others 
are left unresolved as there is no known solution for them. The list is 
provided as a comprehensive overview of the thought process that went into the 
implementation of EFA, and the reasoning behind the design decisions which were 
made.

\begin{itemize}
    \item \textbf{No kind equality.} Singletons cannot be implemented as widely 
    as we would like them to be; essentially such a type is impossible:
    \begin{lstlisting}
    data X (a::k) where
    XF :: X a $\rightarrow$ X f $\rightarrow$ X (f a)
    \end{lstlisting}
    \item \textbf{Non-injective type families.} Specifically, lack of 
    injectivity in type functions means that GHC cannot infer an instantiation 
    of a type variable that appears only under type families. Recently, 
    Microsoft researchers have implemented a GHC modification that allows type 
    functions to be annotated as injective and plan to make it available with 
    the next stable release of the compiler \cite{microsoft}.
    \item \textbf{Functional dependencies are \textit{NOT} equivalent to type 
        families.} For example, given:
    \begin{lstlisting}
    class ... $\Rightarrow$ C a b c| a $\rightarrow$ b
    
    you cannot write
    
    injec :: (C a b, C a b') $\Rightarrow$ b :~: b' 
    \end{lstlisting}
    This is because it is simply not true, no solution for this is 
    currently known \cite{sof}. 
    \item \textbf{Types as propositions.} This is assuming that one exists; 
    simply put, it describes a correspondence between a given logic and a given 
    programming language, where we have "simplification of proofs as evaluation 
    of programs" \cite{props}.
    \item \textbf{Certain invariants are difficult to state and prove.} The 
    solution implemented for this problem was to vastly simply term language 
    and to use informal correctness reasoning. %TTODO: not sure this is 
    %correct, theres a paper on informal corrnectess reasoning that applies to 
    %concurrency in kernels
    \item \textbf{Singletons have a lot of boilerplate code.} Each model 
    requires a constant amount of boilerplate code for each constructor. 
    %TODO: write the boilerplate -- does this mean write the boilerplate code 
    %yourself and adapt it to your specific needs?
    \item \textbf{Defining a typed term from untyped ones.} This had to be done 
    in a semi-safe way; the solution taken was to use abstraction barriers 
    cautiously to construct unsafe data types. %TODO: unsafe datatypes? it just 
    %says unsafe =(
    \item \textbf{The complex relationship between SQL schemata and 
        declarations.} This is specific to the long tables used in Ampersand's 
    database. Database schemata must be converted into a type level 
    representations along with all necessary proofs. The solution implemented 
    for this was to under specify the result type of the existentially 
    quantified function. Rather than fabricating a proof using a function $P$ 
    and a valid input $x$, a decision procedure for $P$ is written and the 
    functions which require such a proof will check that it is true, or throw 
    an error. These functions are only used internally -- they are not part of 
    the interface; such functions would only be called when the input is known 
    to satisfy $P$. This is something that the programmer is able to reason 
    about but not the compiler. %--to the programmer but not the compiler, find 
    %out what this means
\end{itemize} 

